{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7421ad-d11a-4c42-aa48-d3407c579aa5",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - AutoML Pipeline Sample\n",
    "## 03a - AutoML Regression Scoring / Local Explanations\n",
    "\n",
    "This notebook explains how to score a new dataset (as part of a batch process) using a previously trained AutoML model. Moreover, we will leverage the SHAP library to generate local explanations which reflect which features have positively/negatively contributed to the predicted value (median home price).\n",
    "\n",
    "The pipeline defined below takes in the name of the registered model, the training dataset (for feature explanation purposes), and a dataset to be scored. Following scoring and explainability analysis, this pipeline saves a result set to a CSV which is stored in the AML-linked blob store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f851d1-4aea-4705-bfdb-999ee75ccca6",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571fac6-9fab-401b-86fc-8a4003cd376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, command, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed334ad-4769-4f0c-8750-2a142e218d21",
   "metadata": {},
   "source": [
    "### Get connection to Azure ML workspace\n",
    "\n",
    "Update the variables below to reflect your Azure ML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825fad7-3bf9-415f-938f-724b378fc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "    \n",
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "ml_client\n",
    "\n",
    "subscription_id = ''\n",
    "resource_group = ''\n",
    "workspace_name = ''\n",
    "\n",
    "datastore = ml_client.datastores.get_default() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0828846-a334-44ce-9136-73a4d945f400",
   "metadata": {},
   "source": [
    "### Get handles to datastore path containing unscored data, along with the registered dataset used for model training\n",
    "\n",
    "These will be passed as arguments to our pipeline below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a55316-f301-458f-995a-aceb3cbc5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_data_path = f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/{datastore.name}/paths/data/housing_scoring_data/\"\n",
    "\n",
    "raw_dataset = ml_client.data.get(\"Regression_HousingData\", label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b433a-88f3-441e-a430-6052f24b3e36",
   "metadata": {},
   "source": [
    "### Define pipeline\n",
    "\n",
    "Here, our pipeline consists of a single step which performs the following activities:\n",
    "- Load unscored data and training data\n",
    "- Load model from Azure ML registry by name\n",
    "- Generate predictions for unscored data and append to dataset\n",
    "- Generate local model explanations these predictions and append to dataset\n",
    "- Save final scored dataset to CSV in Azure ML-linked blob store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7a115-6a17-4a89-a6e7-31b1215f020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "@pipeline(\n",
    "    description=\"AutoML Regression Scoring Pipeline\",\n",
    ")\n",
    "def automl_regression_scoring(\n",
    "    regression_train_data, regression_validation_data, regression_test_data, model_base_name\n",
    "):\n",
    "    \n",
    "    # define command function for preprocessing the model\n",
    "    scoring_command_func = command(\n",
    "        inputs=dict(\n",
    "            training_data=Input(path=raw_dataset.id,\n",
    "              type=AssetTypes.URI_FILE,\n",
    "              mode=InputOutputModes.RO_MOUNT\n",
    "              ),\n",
    "            scoring_data=Input(path=scoring_data_path, type=AssetTypes.URI_FOLDER, model=InputOutputModes.RO_MOUNT),\n",
    "            model_name='HomePricePredictionModel',\n",
    "            target_column='MedHouseVal'\n",
    "        ),\n",
    "        outputs=dict(\n",
    "            scored_data=Output(type=AssetTypes.URI_FOLDER),\n",
    "        ),\n",
    "        code=\"./scoring_regression.py\",\n",
    "        command=\"python scoring_regression.py \"\n",
    "        + \"--training_data ${{inputs.training_data}} \"\n",
    "        + \"--scoring_data ${{inputs.scoring_data}} \"\n",
    "        + \"--model_name ${{inputs.model_name}} \"\n",
    "        + \"--target_column ${{inputs.target_column}} \"\n",
    "        + \"--scored_data ${{outputs.scored_data}} \",\n",
    "        environment=\"evaluation-environment@latest\",\n",
    "        display_name='Score and Save Data'\n",
    "    )\n",
    "    scoring_node = scoring_command_func()\n",
    "\n",
    "pipeline_scoring = automl_regression_scoring()\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_scoring.settings.default_compute = \"cpucluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488fb63-da45-4aec-9186-519babbce0d5",
   "metadata": {},
   "source": [
    "### Submit pipeline job and await completion\n",
    "\n",
    "Following execution of the pipeline below, we should be able to review our results which are stored in Azure blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844c63b-806e-400f-8cf4-d1d4e45686df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_scoring, experiment_name=\"AutoML_Scoring_Test\"\n",
    ")\n",
    "pipeline_job\n",
    "\n",
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b396a58-5887-40fc-9648-1d8813f8c147",
   "metadata": {},
   "source": [
    "### Explore results\n",
    "\n",
    "From the pipeline run, we can navigate to the outputs and review our saved scored data:\n",
    "\n",
    "#### Run Summary (see Outputs, scored_data):\n",
    "![Pipeline Results 1](img/aml_results1.png \"Pipeline Run Summary\")\n",
    "\n",
    "#### Output Dataset (CSV):\n",
    "![Pipeline Results 2](img/aml_results2.png \"Saved Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
