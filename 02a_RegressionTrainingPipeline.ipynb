{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09f151d-dbe6-4340-93f5-a41e3e6234ed",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - AutoML Pipeline Sample\n",
    "## 02 - AutoML Regression Training\n",
    "\n",
    "This notebook explains how to use a Regression AutoML task inside pipeline by consuming the dataset we previously registered as `Regression_HousingData`. Our pipeline consists of multiple steps which first retrieve our raw training data, then splits into train & test components prior to AutoML training. Here, we are configuring our AutoML job to produce a MLflow model for easy consumption downstream.\n",
    "\n",
    "After training, we perform a champion vs. challenger evaluation by pitting our newly trained model against the current champion (if it exists) to see which model performs better against a common test dataset. If our new model performs better the pipeline continues and the model is added to the registry. If not, the pipeline gracefully ends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19b9f7-2e31-49fe-b734-f873b80fc8d7",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571fac6-9fab-401b-86fc-8a4003cd376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, Input, command, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.automl import regression\n",
    "from azure.ai.ml.entities._job.automl.tabular import TabularFeaturizationSettings\n",
    "from azure.ai.ml.entities import (\n",
    "    Environment\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd75d0-ba36-48b8-af7b-cbad6f90c467",
   "metadata": {},
   "source": [
    "### Get a handle to the AML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825fad7-3bf9-415f-938f-724b378fc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "    \n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b04d94-bc1c-4e3a-b740-d635f2e88c22",
   "metadata": {},
   "source": [
    "### Create compute cluster for training if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823028da-7092-4f2d-bb8f-b55406d3c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = 'cpucluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(compute_name)\n",
    "except Exception as e:\n",
    "    # Define the compute configuration  \n",
    "    cpu_compute_config = AmlCompute(  \n",
    "        name=compute_name,  \n",
    "        type=\"amlcompute\",  \n",
    "        size=\"STANDARD_D3_V2\",  # Specify the VM size  \n",
    "        min_instances=0,  \n",
    "        max_instances=4,  \n",
    "        idle_time_before_scale_down=120  \n",
    "    )  \n",
    "\n",
    "    # Create the compute cluster  \n",
    "    compute_target = ml_client.begin_create_or_update(cpu_compute_config)\n",
    "    \n",
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a85e60-2472-4cea-ae37-7022d3e7e2cc",
   "metadata": {},
   "source": [
    "### Define reusable environments\n",
    "\n",
    "Below, we create environments for data preparation, and for model evaluation. These environments have been defined as conda yaml files and will ensure that our steps will execute within python runtimes that contain all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec1c65-6e3c-4bb1-8bb8-a436664fcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep_env = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"./environments/dataprep.yml\",\n",
    "    name=\"preprocessing-environment\",\n",
    "    description=\"Preprocessing environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(dataprep_env)\n",
    "\n",
    "evaluation_env = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"./environments/evaluation.yml\",\n",
    "    name=\"evaluation-environment\",\n",
    "    description=\"Evaluation environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(evaluation_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01538234-b80f-43e2-9b9b-e416090f5898",
   "metadata": {},
   "source": [
    "### Get handle to registered regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a55316-f301-458f-995a-aceb3cbc5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = ml_client.data.get(\"Regression_HousingData\", label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf24c07-8ca4-4e6e-8093-e750256f0993",
   "metadata": {},
   "source": [
    "### Build AutoML pipeline with steps for data splitting, model training, model evaluation, and model registration\n",
    "\n",
    "All of these steps point towards Python files which have been included in this repository. These python scripts will execute in sequence and carry out all necessary steps to train and register a new regression model using AutoML.\n",
    "\n",
    "Note: the AutoML configuration settings have been adjusted for rapid development. For production runs you will likely look to increase the number of experiments that are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7a115-6a17-4a89-a6e7-31b1215f020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "@pipeline(\n",
    "    description=\"AutoML Regression Pipeline\",\n",
    ")\n",
    "def automl_regression(\n",
    "    regression_train_data, regression_validation_data, regression_test_data, model_base_name\n",
    "):\n",
    "    \n",
    "    # define command function for preprocessing the model\n",
    "    preprocessing_command_func = command(\n",
    "        inputs=dict(\n",
    "            raw_data=Input(path=raw_dataset.id,\n",
    "              type=AssetTypes.URI_FILE,\n",
    "              mode=InputOutputModes.RO_MOUNT\n",
    "              )\n",
    "        ),\n",
    "        outputs=dict(\n",
    "            preprocessed_train_data=Output(type=\"mltable\"),\n",
    "            preprocessed_test_data=Output(type=\"mltable\"),\n",
    "        ),\n",
    "        code=\"./preprocess.py\",\n",
    "        command=\"python preprocess.py \"\n",
    "        + \"--raw_data ${{inputs.raw_data}} \"\n",
    "        + \"--preprocessed_train_data ${{outputs.preprocessed_train_data}} \"\n",
    "        + \"--preprocessed_test_data ${{outputs.preprocessed_test_data}}\",\n",
    "        environment=\"preprocessing-environment@latest\",\n",
    "        display_name='Get and Split Data'\n",
    "    )\n",
    "    preprocess_node = preprocessing_command_func()\n",
    "\n",
    "    # define the AutoML regression task with AutoML function\n",
    "    regression_node = regression(\n",
    "        primary_metric=\"r2_score\",\n",
    "        target_column_name=\"MedHouseVal\",\n",
    "        training_data=preprocess_node.outputs.preprocessed_train_data,\n",
    "        test_data=preprocess_node.outputs.preprocessed_test_data,\n",
    "        featurization=TabularFeaturizationSettings(mode=\"auto\"),\n",
    "        # currently need to specify outputs \"mlflow_model\" explicitly to reference it in following nodes\n",
    "        outputs={\"best_model\": Output(type=\"mlflow_model\")},\n",
    "        display_name='Train Models'\n",
    "    )\n",
    "    # set limits & training\n",
    "    regression_node.set_limits(max_trials=4, max_concurrent_trials=4)\n",
    "    regression_node.set_training(\n",
    "        enable_stack_ensemble=False, enable_vote_ensemble=False, enable_model_explainability=True\n",
    "    )\n",
    "    \n",
    "    # define command function for evaluating the newly trained model (champion v. challenger test)\n",
    "    evaluate_func = command(\n",
    "        inputs=dict(\n",
    "            model_input_path=Input(type=\"mlflow_model\"),\n",
    "            model_base_name='HomePricePredictionModel',\n",
    "            test_data=Input(type=\"mltable\"),\n",
    "            target_column='MedHouseVal'\n",
    "        ),\n",
    "        outputs=dict(\n",
    "             comparison_metrics=Output(type=\"uri_folder\"),\n",
    "        ),\n",
    "        code=\"./evaluate.py\",\n",
    "        command=\"python evaluate.py \"\n",
    "        + \"--model_input_path ${{inputs.model_input_path}} \"\n",
    "        + \"--model_base_name ${{inputs.model_base_name}} \"\n",
    "        + \"--test_data ${{inputs.test_data}} \"\n",
    "        + \"--target_column ${{inputs.target_column}} \"\n",
    "        + \"--comparison_metrics ${{outputs.comparison_metrics}}\",\n",
    "        environment=\"evaluation-environment@latest\",\n",
    "        display_name='Evaluate Model (Champion vs. Challenger)'\n",
    "    )\n",
    "    evaluate_model = evaluate_func(test_data=preprocess_node.outputs.preprocessed_test_data, model_input_path=regression_node.outputs.best_model)\n",
    "\n",
    "    # define command function for registering the model\n",
    "    command_func = command(\n",
    "        inputs=dict(\n",
    "            model_input_path=Input(type=\"mlflow_model\"),\n",
    "            model_base_name='HomePricePredictionModel',\n",
    "            comparison_metrics=Input(type=\"uri_folder\"),\n",
    "        ),\n",
    "        outputs=dict(\n",
    "            registered_model_details=Output(type=\"uri_folder\")\n",
    "        ),\n",
    "        code=\"./register.py\",\n",
    "        command=\"python register.py \"\n",
    "        + \"--model_input_path ${{inputs.model_input_path}} \"\n",
    "        + \"--model_base_name ${{inputs.model_base_name}} \"\n",
    "        + \"--registered_model_details ${{outputs.registered_model_details}} \"\n",
    "        + \"--comparison_metrics ${{inputs.comparison_metrics}} \",\n",
    "        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "        display_name='Register Model'\n",
    "    )\n",
    "    register_model = command_func(model_input_path=regression_node.outputs.best_model, comparison_metrics=evaluate_model.outputs.comparison_metrics)\n",
    "\n",
    "pipeline_regression = automl_regression()\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_regression.settings.default_compute = \"cpucluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c58dd-55b6-4c4d-8341-d072e5e88df9",
   "metadata": {},
   "source": [
    "### Submit pipeline job\n",
    "\n",
    "Step below will await pipeline completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844c63b-806e-400f-8cf4-d1d4e45686df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_regression, experiment_name=\"AutoML_Regression_Test\"\n",
    ")\n",
    "pipeline_job\n",
    "\n",
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ed8e5-bd22-4f56-aa06-9a4022346e86",
   "metadata": {},
   "source": [
    "### Confirm model registration\n",
    "\n",
    "After the first run of the pipeline, a model should be added to your workspace registry by default. You can visit the registry to confirm a new model has been added as shown below:\n",
    "\n",
    "![Azure ML Model](img/aml_model.png \"Registered Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
