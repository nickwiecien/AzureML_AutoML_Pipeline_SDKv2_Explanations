{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1532b90d-8c64-45c1-96dc-e939c06579fe",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - AutoML Pipeline Sample\n",
    "## 01 - Environment Creation\n",
    "\n",
    "The notebook below is part of a set of notebooks designed to train, evaluate, and register a custom regression/classification model using Azure ML's AutoML capabilities. Then as part of a batch process, that model will be used to score a new dataset, compute SHAP values for all scored data, and write those results as a CSV to an AML-linked blob store. These notebooks are designed to be run in sequenced based on the number/letter designation in their title.\n",
    "\n",
    "This notebook contains logic for saving, uploading, and registering CSV datasets to an Azure ML-linked blob storage account. \n",
    "\n",
    "Using built-in regression/classification datasets from Scikit-Learn, we first load and save the California Housing and Iris Setosa datasets as CSV files locally (Note: For demonstration purposes, we will save two copies of the same data for both training and scoring. In most production scenarios these would be distinct datasets). Then, using the Azure Machine Learning File System utility, we upload these files to blob storage and register these datasets (`Regression_HousingData` and `Classification_IrisData`) to be consumed in future pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a0f94-c7e5-44ab-b204-03790e771d8c",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25034eb3-48b2-4c85-90f2-09ac4ed72607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient  \n",
    "from azure.ai.ml.entities import Data  \n",
    "from azure.identity import DefaultAzureCredential  \n",
    "from azure.ai.ml.constants import AssetTypes  \n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_iris\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e324e3-1eca-44e6-a3b0-95358ec3f5c3",
   "metadata": {},
   "source": [
    "### Load sample datasets from Scikit-Learn and create unified dataframes with both input and target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3842e5-352f-4eef-a1ea-68bbded7abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the California housing dataset  \n",
    "california_housing = fetch_california_housing()  \n",
    "X, y = pd.DataFrame(california_housing.data, columns=california_housing.feature_names), pd.DataFrame(california_housing.target, columns=california_housing.target_names)  \n",
    "housing_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Load the iris dataset  \n",
    "iris = load_iris()  \n",
    "X, y = pd.DataFrame(iris.data, columns=iris.feature_names), pd.DataFrame(iris.target, columns=['Plant'])\n",
    "iris_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3814c46-5277-4e72-b2c5-b63f3b4324de",
   "metadata": {},
   "source": [
    "### Save datasets locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eac3c7-bf51-4feb-a0aa-0f19db0ed7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./housing_data', exist_ok=True)\n",
    "os.makedirs('./iris_data', exist_ok=True)\n",
    "\n",
    "housing_data.to_csv('./housing_data/regression_training_dataset.csv', index=False)\n",
    "iris_data.to_csv('./iris_data/classification_training_dataset.csv', index=False)\n",
    "\n",
    "housing_data.to_csv('./housing_data/regression_scoring_dataset.csv', index=False)\n",
    "iris_data.to_csv('./iris_data/classification_scoring_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec3379-fea5-476d-ac08-6ed2a1a7c45b",
   "metadata": {},
   "source": [
    "### Get a connection to your Azure ML workspace\n",
    "\n",
    "Update the values for `subscription_id`, `resource_group`, and `workspace_name` to reflect the attributes associated with your resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839242a-6f1b-495e-a1af-a3f31c62980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define workspace details   \n",
    "subscription_id = ''\n",
    "resource_group = ''\n",
    "workspace_name = ''  \n",
    "  \n",
    "# Authenticate to Azure  \n",
    "credential = DefaultAzureCredential()  \n",
    "  \n",
    "# Connect to your workspace  \n",
    "ml_client = MLClient.from_config(credential=credential, workspace=workspace_name)\n",
    "\n",
    "datastore = ml_client.datastores.get_default() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5153b-9f3e-44d3-bfda-c8d1d9567807",
   "metadata": {},
   "source": [
    "### Upload regression & classification data to the default AML blobstore using the `AzureMachineLearningFileSystem` utility\n",
    "\n",
    "The code below will upload the contents of our newly created `housing_data` and `iris_data` directories to the relative path specified in the `upload(...)` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae055141-9d1b-4489-b986-27d31e28b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.fsspec import AzureMachineLearningFileSystem\n",
    "# instantiate file system using following URI\n",
    "fs_uri = f'azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/{datastore.name}/paths/'\n",
    "print(fs_uri)\n",
    "fs = AzureMachineLearningFileSystem(fs_uri)\n",
    "\n",
    "# you can specify recursive as False to upload a file\n",
    "fs.upload(lpath='housing_data', rpath='data/housing_data', recursive=True, **{'overwrite': 'MERGE_WITH_OVERWRITE'})\n",
    "\n",
    "# you need to specify recursive as True to upload a folder\n",
    "fs.upload(lpath='iris_data', rpath='data/iris_data', recursive=True, **{'overwrite': 'MERGE_WITH_OVERWRITE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228c866-b743-4274-9acc-e19e0d9fbeae",
   "metadata": {},
   "source": [
    "### Confirm data upload\n",
    "\n",
    "You should now be able to see your uploaded CSVs in the AML-linked blob store as is shown below:\n",
    "\n",
    "![Azure ML Data](img/aml_data.png \"Uploaded Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f36ce-2cfe-4e32-87a8-1529f5670102",
   "metadata": {},
   "source": [
    "### Register classification/regression training datasets\n",
    "\n",
    "Here, we will created registered (read: saved & versioned) copies of our uploaded data to simplify usage in subsequent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae52c1-3ebb-421a-8b37-d4d584505f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset  \n",
    "housing_data_uri = fs_uri + 'data/housing_data/regression_training_dataset.csv'\n",
    "data_asset = Data(  \n",
    "    path=housing_data_uri,  \n",
    "    type=AssetTypes.URI_FILE,  \n",
    "    description='California housing dataset from Scikit-learn to be used in building a model for predicting median home price',  \n",
    "    name='Regression_HousingData',  \n",
    ")  \n",
    "\n",
    "# Create or update the dataset  \n",
    "registered_data_asset = ml_client.data.create_or_update(data_asset)  \n",
    "\n",
    "print(f\"Dataset {registered_data_asset.name} is registered.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920bc62-ad6e-46ed-bf0b-72c168560488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the dataset  \n",
    "iris_data_uri = fs_uri + 'data/iris_data/classification_training_dataset.csv'\n",
    "data_asset = Data(  \n",
    "    path=iris_data_uri,  \n",
    "    type=AssetTypes.URI_FILE,  \n",
    "    description='Iris Setosa dataset from Scikit-learn to be used in building a model for classifying plant type based on attributes',  \n",
    "    name='Classification_IrisData',  \n",
    ")  \n",
    "\n",
    "# Create or update the dataset  \n",
    "registered_data_asset = ml_client.data.create_or_update(data_asset)  \n",
    "\n",
    "print(f\"Dataset {registered_data_asset.name} is registered.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc17eb-636f-4566-b387-2699f5e870ca",
   "metadata": {},
   "source": [
    "### Confirm Dataset creation\n",
    "\n",
    "After registering your datasets, they should appear within your AML workspace as registered assets as shown below:\n",
    "\n",
    "![Azure ML Datasets](img/aml_datasets.png \"Registered Datasets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
